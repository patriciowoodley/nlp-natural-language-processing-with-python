{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Assessment\n",
    "This assessment is very much like the Text Classification Project we just completed, and the dataset is very similar.\n",
    "\n",
    "The **moviereviews2.tsv** dataset contains the text of 6000 movie reviews. 3000 are positive, 3000 are negative, and the text has been preprocessed as a tab-delimited file. As before, labels are given as `pos` and `neg`.\n",
    "\n",
    "We've included 20 reviews that contain either `NaN` data, or have strings made up of whitespace.\n",
    "\n",
    "For more information on this dataset visit http://ai.stanford.edu/~amaas/data/sentiment/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task #1: Perform imports and load the dataset into a pandas DataFrame\n",
    "For this exercise you can load the dataset from `'../TextFiles/moviereviews2.tsv'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../TextFiles/moviereviews2.tsv', sep=\"\\t\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task #2: Check for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "label      0\n",
       "review    20\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Check for NaN values:\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(0, 2)\n(0, 2)\n"
     ]
    }
   ],
   "source": [
    "# Check for whitespace strings (it's OK if there aren't any!):\n",
    "print(df.dropna()[df.dropna().review.str.isspace()].shape)\n",
    "\n",
    "print(df.dropna()[df.dropna().label.str.isspace()].shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task #3: Remove NaN values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task #4: Take a quick look at the `label` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       pos\n",
       "1       pos\n",
       "2       pos\n",
       "3       neg\n",
       "4       pos\n",
       "       ... \n",
       "5995    pos\n",
       "5996    neg\n",
       "5997    neg\n",
       "5998    pos\n",
       "5999    pos\n",
       "Name: label, Length: 5980, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "df.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task #5: Split the data into train & test sets:\n",
    "You may use whatever settings you like. To compare your results to the solution notebook, use `test_size=0.33, random_state=42`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[\"review\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task #6: Build a pipeline to vectorize the date, then train and fit a model\n",
    "You may use whatever model you like. To compare your results to the solution notebook, use `LinearSVC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfid', TfidfVectorizer()), ('clf', LinearSVC())])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline( [ \n",
    "                        (\"tfid\", TfidfVectorizer()),\n",
    "                        (\"clf\", LinearSVC())\n",
    "                    ])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task #7: Run predictions and analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a prediction set\n",
    "predictions = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[900  91]\n [ 63 920]]\n"
     ]
    }
   ],
   "source": [
    "# Report the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n         neg       0.93      0.91      0.92       991\n         pos       0.91      0.94      0.92       983\n\n    accuracy                           0.92      1974\n   macro avg       0.92      0.92      0.92      1974\nweighted avg       0.92      0.92      0.92      1974\n\n"
     ]
    }
   ],
   "source": [
    "# Print a classification report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9219858156028369"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "# Print the overall accuracy\n",
    "import sklearn.metrics\n",
    "\n",
    "sklearn.metrics.accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     C:\\Users\\patricio.woodley\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"vader_lexicon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting nltk\n  Downloading nltk-3.6.2-py3-none-any.whl (1.5 MB)\nRequirement already satisfied: joblib in c:\\users\\patricio.woodley\\anaconda3\\envs\\nlp\\lib\\site-packages (from nltk) (1.0.1)\nCollecting regex\n  Downloading regex-2021.4.4-cp39-cp39-win_amd64.whl (270 kB)\nRequirement already satisfied: tqdm in c:\\users\\patricio.woodley\\anaconda3\\envs\\nlp\\lib\\site-packages (from nltk) (4.60.0)\nRequirement already satisfied: click in c:\\users\\patricio.woodley\\anaconda3\\envs\\nlp\\lib\\site-packages (from nltk) (7.1.2)\nInstalling collected packages: regex, nltk\nSuccessfully installed nltk-3.6.2 regex-2021.4.4\nNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python392jvsc74a57bd03f4646192991bf6f8f2308881c9239a8c343d30f3ea8aedbf00b62793fda26ad",
   "display_name": "Python 3.9.2 64-bit ('nlp': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}